{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comic(img):\n",
    "    # do edge detection on a grayscale image\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGRA2GRAY)\n",
    "    edges = cv2.blur(gray, (3, 3)) # this blur gets rid of some noise\n",
    "    edges = cv2.Canny(edges, 50, 150, apertureSize=3) # this is the edge detection\n",
    "    cv2.imshow('canny', edges)\n",
    "    # the edges are a bit thin, this blur and threshold make them a bit fatter\n",
    "    kernel = np.ones((3,3), dtype=np.float) / 12.0\n",
    "    edges = cv2.filter2D(edges, 0, kernel)\n",
    "    edges = cv2.threshold(edges, 50, 255, 0)[1]\n",
    "    cv2.imshow('threshlod', edges)\n",
    "    # and back to colour...\n",
    "    edges = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)\n",
    "    cv2.imshow('colored edge', edges)\n",
    "    # this is the expensive operation, it blurs things but keeps track of\n",
    "    # colour boundaries or something, heck, just play with it\n",
    "    shifted = cv2.pyrMeanShiftFiltering(img, 5, 20)\n",
    "    cv2.imshow('shifted', shifted)\n",
    "    # now compose with the edges, the edges are white so take them away\n",
    "    # to leave black\n",
    "    return cv2.subtract(shifted, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(img_rgb):\n",
    "    numDownSamples = 2 # number of downscaling steps\n",
    "    numBilateralFilters = 7  # number of bilateral filtering steps\n",
    "\n",
    "    # -- STEP 1 --\n",
    "    # downsample image using Gaussian pyramid\n",
    "    img_color = img_rgb\n",
    "    for i in range(numDownSamples):\n",
    "        img_color = cv2.pyrDown(img_color)\n",
    "\n",
    "    # repeatedly apply small bilateral filter instead of applying\n",
    "    # one large filter\n",
    "    for i in range(numBilateralFilters):\n",
    "        img_color = cv2.bilateralFilter(img_color, 9, 9, 7)\n",
    "\n",
    "    # upsample image to original size\n",
    "    for i in range(numDownSamples):\n",
    "        img_color = cv2.pyrUp(img_color)\n",
    "\n",
    "    # -- STEPS 2 and 3 --\n",
    "    # convert to grayscale and apply median blur\n",
    "    img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
    "    img_blur = cv2.medianBlur(img_gray, 7)\n",
    "\n",
    "    # -- STEP 4 --\n",
    "    # detect and enhance edges\n",
    "    img_edge = cv2.adaptiveThreshold(img_blur, 255,\n",
    "        cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 9, 2)\n",
    "\n",
    "    # -- STEP 5 --\n",
    "    # convert back to color so that it can be bit-ANDed\n",
    "    # with color image\n",
    "    img_edge = cv2.cvtColor(img_edge, cv2.COLOR_GRAY2RGB)\n",
    "    return cv2.bitwise_and(img_color, img_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 800, 3) (1200, 1600, 3)\n",
      "(300, 400, 3) (1200, 1600, 3)\n",
      "(600, 800, 3) (1200, 1600, 3)\n",
      "(1200, 1600, 3) (1200, 1600, 3)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('../../../car_dataset/AC_Schnitzer-GP3_10_Concept_10.jpg', cv2.IMREAD_COLOR)\n",
    "# for i in range(5):\n",
    "#     blur = cv2.bilateralFilter(img, 9, 9, 7, cv2.BORDER_TRANSPARENT)\n",
    "# resize = cv2.resize(blur, dsize=(256, 256), interpolation=cv2.INTER_LINEAR_EXACT)\n",
    "img_color = img\n",
    "for i in range(2):\n",
    "    img_color = cv2.pyrDown(img_color)\n",
    "    print(img_color.shape, img.shape)\n",
    "num_iter = 7\n",
    "for i in range(num_iter):\n",
    "    img_color = cv2.bilateralFilter(img_color, d=9, sigmaColor=9, sigmaSpace=7)\n",
    "for i in range(2):\n",
    "    img_color = cv2.pyrUp(img_color)\n",
    "    print(img_color.shape, img.shape)\n",
    "\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "img_blur = cv2.medianBlur(img_gray, 7)\n",
    "img_edge = cv2.adaptiveThreshold(img_blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 5 , 2)\n",
    "cv2.imshow('img_edge', img_edge)\n",
    "img_edge = cv2.cvtColor(img_edge, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "cartoon = cv2.bitwise_and(img_color, img_edge)\n",
    "\n",
    "comic1 = comic(img)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "# cv2.imshow('blur', blur)\n",
    "cv2.imshow('img_color', img_color)\n",
    "cv2.imshow('img_edge', img_edge)\n",
    "cv2.imshow('render', render(img))\n",
    "cv2.imshow('cartoon', cartoon)\n",
    "cv2.imshow('comic', comic1)\n",
    "# cv2.imshow('resize', resize)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(186, 149, 3)\n",
      "(186, 149, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load two images\n",
    "img1 = cv2.imread('2502287818_41e4b0c4fb_z.jpg')\n",
    "img2 = cv2.imread('logo.jpg')\n",
    "# I want to put logo on top-left corner, So I create a ROI\n",
    "rows,cols,channels = img2.shape\n",
    "roi = img1[0:rows, 0:cols]\n",
    "# Now create a mask of logo and create its inverse mask also\n",
    "img2gray = cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
    "ret, mask = cv2.threshold(img2gray, 10, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow('threshold ', mask)\n",
    "\n",
    "mask_inv = cv2.bitwise_not(mask)\n",
    "cv2.imshow('mask_inv', mask_inv)\n",
    "\n",
    "# Now black-out the area of logo in ROI\n",
    "img1_bg = cv2.bitwise_and(roi,roi,mask = mask_inv)\n",
    "cv2.imshow('bitwise_and1', img1_bg)\n",
    "\n",
    "# Take only region of logo from logo image.\n",
    "img2_fg = cv2.bitwise_and(img2,img2,mask = mask)\n",
    "cv2.imshow('bitwise_and2', img2_fg)\n",
    "\n",
    "# Put logo in ROI and modify the main image\n",
    "dst = cv2.add(img1_bg,img2_fg)\n",
    "cv2.imshow('dst', dst)\n",
    "img1[0:rows, 0:cols ] = dst\n",
    "print(img1[0:rows, 0:cols ].shape)\n",
    "print(img1[:rows, :cols].shape)\n",
    "cv2.imshow('res',img1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_image=np.zeros((1200, 3200, 3))\n",
    "print(merged_image.shape)\n",
    "\n",
    "print(img2[:186, :149])\n",
    "print(\"---------------------\")\n",
    "print(img2[:, :149])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(20)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 425 and the array at index 1 has size 149",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-0aae2bf9b777>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'vis'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mvis2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'vis'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvis2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 425 and the array at index 1 has size 149"
     ]
    }
   ],
   "source": [
    "vis = np.concatenate((img1, img2), axis=0)\n",
    "cv2.imshow('vis', vis)\n",
    "vis2 = np.concatenate((img1, img2), axis=0)\n",
    "cv2.imshow('vis', vis2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "room2[np.where(logo_mask == 255)] = logo[np.where(logo_mask == 255)]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
